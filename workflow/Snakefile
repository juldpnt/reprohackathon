# Here we define the accessions to be used in the analysis
# Un/comment the lines below to change the number of accessions to be downloaded
SAMPLES = [
            "SRR10379721",
            # "SRR10379722",
            # "SRR10379723",
            # "SRR10379724",
            # "SRR10379725",
            # "SRR10379726"
            ]

# -------- Target rules
# This rule will change after each next step in the project is reached
rule all:
    """
    Target rule, the input is the output of the DAG made by snakemake
    Comment/Uncomment lines below to change the target rule for debugging purposes
    """
    input:
        # expand("tmp/genome_index/genome_index.sam", sample=SAMPLES)
        # "tmp/reference.fasta", "tmp/reference.gff",
        # expand("tmp/raw_fastq/{sample}.fastq", sample=SAMPLES)
        "tmp/genome_index"

# -------- Part 1: Download the accession files
rule get_fastq_files:
    output:
        fastq="tmp/raw_fastq/{sample}.fastq"
    container: 
        "docker://juldpnt/reprohackaton_8:sratoolkit" 
    shell:
        # """
        # fasterq-dump --threads 4 --progress {wildcards.sample} > {output.fastq}
        # """
        # Uncomment the lines below to download only 1000 reads per accession and comment the lines above
        """
        fastq-dump --stdout -X 1000 {wildcards.sample} > {output.fastq}
        """

rule trimming:
    input:
        fastq="tmp/raw_fastq/{sample}.fastq"
    output:
        fq="tmp/trimmed_fastq/{sample}_trimmed.fq",
    container:
        "docker://vibsinglecellnf/trimgalore:trimgalore-0.6.7-cutadapt-4.2"
    shell:
    # rendre la sortie du fichier plus propre avec le param -O (erreur avec le snakefile)
        """
        trim_galore -q 20 --phred33 --length 25 {input.fastq}
        mv {wildcards.sample}_trimmed.fq tmp/trimmed_fastq/{wildcards.sample}_trimmed.fq
        mv {wildcards.sample}.fastq_trimming_report.txt tmp/trimmed_fastq/{wildcards.sample}_trimming_report.txt
        """

rule download_external_files:
    output:
        reference="tmp/reference.fasta",
        annotation="tmp/reference.gff"
    container:
        "docker://juldpnt/reprohackaton_8:alpine"
    shell:
        """
        wget -O reference.fasta "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=CP000253.1&rettype=fasta"
        mv reference.fasta tmp/reference.fasta
        wget -O reference.gff "https://www.ncbi.nlm.nih.gov/sviewer/viewer.cgi?db=nuccore&report=gff3&id=CP000253.1"
        mv reference.gff tmp/reference.gff
        """

rule create_index:
    input:
        reference="tmp/reference.fasta"
    output:
        directory("tmp/genome_index")
    container:
        "docker://biocontainers/bowtie:v1.2.2dfsg-4-deb_cv1"
    shell:
        """
        mkdir -p {output}
        bowtie-build {input.reference} {output}/reference
        """

# rule mapping:
#     input:
#         trimmed="../results/trimmed_reads/{sample}_trimmed.fastq",
#         genome_index="../results/genome_index/genome_index.sam"
#     output:
#         mapped="../results/mapped_reads/{sample}_mapped.bam"
#     container: 
#         "docker://biocontainers/fastqc"
#     shell:
#         """
#         bowtie -p 1 -S {input.genome_index} {input.trimmed} | \
#         samtools sort -@ 1 {output.mapped} \
#         samtools index {output.mapped}
#         """