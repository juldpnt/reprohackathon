# Here we define the accessions to be used in the analysis
# Un/comment the lines below to change the number of accessions to be downloaded
SAMPLES = [
            "SRR10379721",
            "SRR10379722",
            "SRR10379723",
            "SRR10379724",
            "SRR10379725",
            "SRR10379726"
            ]

# -------- Target rules
# This rule will change after each next step in the project is reached
rule all:
    """
    Target rule, the input is the output of the DAG made by snakemake
    Comment/Uncomment lines below to change the target rule for debugging purposes
    """
    input:
        # "tmp/reference.fasta", "tmp/reference.gff", 
        # expand("tmp/raw_fastq/{sample}.fastq", sample=SAMPLES),
        # "tmp/genome_index", 
        # expand("tmp/mapped_reads/{sample}_mapped.sam", sample=SAMPLES),
        "tmp/counts.txt"

# -------- DOWNLOADING REFERENCE GENOME AND ANNOTATION FILES
rule download_external_files:
    """
    This rule is responsible for downloading the reference genome and annotation files.
    """
    output:
        reference="tmp/reference.fasta",
        annotation="tmp/reference.gff"
    container:
        "docker://juldpnt/reprohackaton_8:alpine"
    shell:
        # The files are downloaded using wget and then moved to the tmp folder 
        """
        wget -O reference.fasta "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=CP000253.1&rettype=fasta"
        mv reference.fasta tmp/reference.fasta
        wget -O annots.gff "https://www.ncbi.nlm.nih.gov/sviewer/viewer.cgi?db=nuccore&report=gff3&id=CP000253.1"
        mv annots.gff tmp/annots.gff
        """

# --------  APPLY FOLLOWING RULES TO EACH SAMPLE
rule get_fastq_files:
    """
    This rule is responsible for downloading the fastq files for each sample. 
    It uses the sratoolkit container to run the fastq-dump command, which downloads the fastq file for a given sample.
    """
    output:
        fastq="tmp/raw_fastq/{sample}.fastq"
    container: 
        "docker://juldpnt/reprohackaton_8:sratoolkit" 
    shell:
        # """
        # fasterq-dump --threads 4 --progress {wildcards.sample} > {output.fastq}
        # """
        # Uncomment the lines below to download only 1000 reads per accession with the -X 1000 arg and comment the lines above
        """
        fastq-dump --stdout {wildcards.sample} > {output.fastq}
        """

rule trimming:
    """
    This rule is responsible for trimming the fastq files for each sample using trim galore container.
    """
    input:
        fastq="tmp/raw_fastq/{sample}.fastq"
    output:
        fq="tmp/trimmed_fastq/{sample}_trimmed.fq",
    container:
        "docker://vibsinglecellnf/trimgalore:trimgalore-0.6.7-cutadapt-4.2"
    shell:
        # The fastq files are trimmed usgin trim galore, the output files are then moved to the tmp folder
        """
        trim_galore -q 20 --phred33 --length 25 {input.fastq}
        mv {wildcards.sample}_trimmed.fq tmp/trimmed_fastq/{wildcards.sample}_trimmed.fq
        mv {wildcards.sample}.fastq_trimming_report.txt tmp/trimmed_fastq/{wildcards.sample}_trimming_report.txt
        """

rule create_index:
    """
    This rule is responsible for creating the index for the reference genome using bowtie container.
    """
    input:
        reference="tmp/reference.fasta"
    output:
        directory("tmp/genome_index")
    container:
        "docker://biocontainers/bowtie:v1.2.2dfsg-4-deb_cv1"
    shell:
        """
        mkdir -p {output}
        bowtie-build {input.reference} {output}/reference
        """

rule mapping:
    """
    This rule is responsible for mapping the trimmed fastq files to the reference genome using bowtie container.
    """
    input:
        trimmed="tmp/trimmed_fastq/{sample}_trimmed.fq",
        genome_index="tmp/genome_index"
    output:
        mapped="tmp/mapped_reads/{sample}_mapped.sam"
    container: 
        "docker://biocontainers/bowtie:v1.2.2dfsg-4-deb_cv1"
    shell:
        """
        bowtie --no-unal --threads 4 --sam {input.genome_index}/reference {input.trimmed} {output.mapped}
        """
# --------  APPLY FOLLOWING RULES ONCE AFTER ALL SAMPLES ARE PROCESSED
rule count:
    """
    This rule is responsible for counting the reads mapped to each gene using featureCounts container.
    """
    input:
        reference="tmp/annots.gff",
        mapped_sam_files=expand("tmp/mapped_reads/{sample}_mapped.sam", sample=SAMPLES)
    output:
        counted="tmp/counts.txt"
    container:
        "docker://biocontainers/subread:v1.6.3dfsg-1-deb_cv1"
    shell:
        """
        featureCounts --extraAttributes Name -t gene -g ID -F GTF -T 3 -a {input.reference} -o {output.counted} {input.mapped_sam_files}
        """
rule scriptR:
    """
    This rule is responsible for running the R script that will generate the plots.
    """
    input:
        counts="tmp/counts.txt"
    output:
        plot="tmp/plot.png"
    container:
        "docker://juldpnt/reprohackaton_8:alpine"
    shell:
        """
        Rscript scripts/plot.R {input.counts} {output.plot}
        """