configfile: "config.yaml"

# Un/comment the lines below to change the number of accessions to be downloaded
SAMPLES = config["samples"]
TMP = config["tmp"]
RESULTS = config["results"]
WORKFLOW = config["workflow"]

# -------- Target rules

# This rule will change after each next step in the project is reached
rule all:
    """
    Target rule, the input is the output of the DAG made by snakemake
    Comment/Uncomment lines below to change the target rule for debugging purposes
    """
    input:
        # TMP + "/reference.fasta", TMP + "/annots.gff", 
        # expand(TMP + "/raw_fastq/{sample}.fastq", sample=SAMPLES),
        # TMP + "/genome_index", 
        # expand(TMP + "/mapped_reads/{sample}_mapped.sam", sample=SAMPLES),
        # TMP + "/counts.txt", 
        RESULTS + "/MA_plot.png"

# -------- DOWNLOADING REFERENCE GENOME AND ANNOTATION FILES

rule download_reference_genome:
    """
    This rule is responsible for downloading the reference genome.
    """
    output:
        reference= TMP + "/reference.fasta",
    container:
        "docker://juldpnt/reprohackaton_8:alpine"
    shell:
        # The files are downloaded using wget and then moved to the tmp folder 
        """
        mkdir -p {TMP}
        wget -O reference.fasta "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=CP000253.1&rettype=fasta"
        mv reference.fasta {TMP}/reference.fasta
        """

rule download_annotation:
    """
    This rule is responsible for downloading the annotation file.
    """
    output:
        annotation= TMP + "/annots.gff"
    container:
        "docker://juldpnt/reprohackaton_8:alpine"
    shell:
        # The file is downloaded using wget and then moved to the tmp folder 
        """
        mkdir -p {TMP}
        wget -O annots.gff "https://www.ncbi.nlm.nih.gov/sviewer/viewer.cgi?db=nuccore&report=gff3&id=CP000253.1"
        mv annots.gff {TMP}/annots.gff
        """
# --------  APPLY FOLLOWING RULES TO EACH SAMPLE

rule get_fastq_files:
    """
    This rule is responsible for downloading the fastq files for each sample. 
    It uses the sratoolkit container to run the fastq-dump command, which downloads the fastq file for a given sample.
    """
    output:
        fastq= TMP + "/raw_fastq/{sample}.fastq"
    container: 
        "docker://juldpnt/reprohackaton_8:sratoolkit" 
    shell:
        # """
        # fasterq-dump --threads 4 --progress {wildcards.sample} > {output.fastq}
        # """
        # Uncomment the lines below to download only 1000 reads per accession with the -X 1000 arg and comment the lines above
        """
        fastq-dump --stdout -X 1000 {wildcards.sample} > {output.fastq}
        """

rule trimming:
    """
    This rule is responsible for trimming the fastq files for each sample using trim galore container.
    """
    input:
        fastq= TMP + "/raw_fastq/{sample}.fastq"
    output:
        fq= TMP + "/trimmed_fastq/{sample}_trimmed.fq",
    container:
        "docker://vibsinglecellnf/trimgalore:trimgalore-0.6.7-cutadapt-4.2"
    shell:
        # The fastq files are trimmed usgin trim galore, the output files are then moved to the tmp folder
        """
        trim_galore -q 20 --phred33 --length 25 {input.fastq}
        mv {wildcards.sample}_trimmed.fq {config[tmp]}/trimmed_fastq/{wildcards.sample}_trimmed.fq
        mv {wildcards.sample}.fastq_trimming_report.txt {TMP}/trimmed_fastq/{wildcards.sample}_trimming_report.txt
        """

rule create_index:
    """
    This rule is responsible for creating the index for the reference genome using bowtie container.
    """
    input:
        reference= TMP + "/reference.fasta"
    output:
        directory(TMP + "/genome_index")
    container:
        "docker://biocontainers/bowtie:v1.2.2dfsg-4-deb_cv1"
    shell:
        """
        mkdir -p {output}
        bowtie-build {input.reference} {output}/reference
        """

rule mapping:
    """
    This rule is responsible for mapping the trimmed fastq files to the reference genome using bowtie container.
    """
    input:
        trimmed= TMP + "/trimmed_fastq/{sample}_trimmed.fq",
        genome_index= TMP + "/genome_index"
    output:
        mapped= TMP + "/mapped_reads/{sample}_mapped.sam"
    container: 
        "docker://biocontainers/bowtie:v1.2.2dfsg-4-deb_cv1"
    shell:
        """
        bowtie --no-unal --threads 4 --sam {input.genome_index}/reference {input.trimmed} {output.mapped}
        """

# --------  APPLY FOLLOWING RULES ONCE AFTER ALL SAMPLES ARE PROCESSED
rule count:
    """
    This rule is responsible for counting the reads mapped to each gene using featureCounts container.
    """
    input:
        reference= TMP +"/annots.gff",
        mapped_sam_files=expand(TMP + "/mapped_reads/{sample}_mapped.sam", sample=SAMPLES)
    output:
        counted= TMP + "/counts.txt"
    container:
        "docker://biocontainers/subread:v1.6.3dfsg-1-deb_cv1"
    shell:
        """
        featureCounts --extraAttributes Name -t gene -g ID -F GTF -T 3 -a {input.reference} -o {output.counted} {input.mapped_sam_files}
        """

rule scriptR:
    """
    This rule is responsible for running the R script that will generate the final plots.
    """
    input:
        counts= TMP + "/counts.txt"
    output:
        plot= RESULTS + "/MA_plot.png"
    container:
        "docker://juldpnt/reprohackaton_8:deseq2"
    shell:
        """
        mkdir -p {RESULTS}
        Rscript {WORKFLOW}/script/plot.R {input.counts} {output.plot}
        """