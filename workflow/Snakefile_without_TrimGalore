configfile: "config.yaml"

# -------- Global variables

# Define the input and outputs

SAMPLES = config["samples"]
PLOTS = config["plots"]

# Define the folders

TMP = config["tmp"]
RESULTS = config["results"]
WORKFLOW = config["workflow"]
THREADS = config["threads"]

# Define the container images
BASE = config["containers"]["base"]
SRATOOLKIT = config["containers"]["sratoolkit"]
TRIMGALORE = config["containers"]["trimgalore"]
BOWTIE = config["containers"]["bowtie"]["latest"]
SUBREAD = config["containers"]["subread"]["latest"]
RSCRIPT = config["containers"]["Rscript"]

# -------- Target rules

# This rule will change after each next step in the project is reached
rule all:
    """
    Target rule, the input is the output of the DAG made by snakemake
    Comment/Uncomment lines below to change the target rule for debugging purposes
    """
    input:
        # TMP + "/reference.fasta", TMP + "/annots.gff", 
        # expand(TMP + "/raw_fastq/{sample}.fastq", sample=SAMPLES),
        # TMP + "/genome_index", 
        # expand(TMP + "/mapped_reads/{sample}_mapped.sam", sample=SAMPLES),
        # TMP + "/counts.txt", 
        expand(RESULTS + "/{plot}.png", plot=PLOTS)

# -------- DOWNLOADING REFERENCE GENOME AND ANNOTATION FILES

rule download_reference_genome:
    """
    This rule is responsible for downloading the reference genome.
    """
    output:
        reference= TMP + "/reference.fasta",
    container:
        BASE
    shell:
        # The files are downloaded using wget and then moved to the tmp folder 
        """
        mkdir -p {TMP}
        wget -O reference.fasta "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=CP000253.1&rettype=fasta"
        mv reference.fasta {output.reference}
        """

rule download_annotation:
    """
    This rule is responsible for downloading the annotation file.
    """
    output:
        annotation= TMP + "/annots.gff"
    container:
        BASE
    shell:
        # The file is downloaded using wget and then moved to the tmp folder 
        """
        mkdir -p {TMP}
        wget -O annots.gff "https://www.ncbi.nlm.nih.gov/sviewer/viewer.cgi?db=nuccore&report=gff3&id=CP000253.1"
        mv annots.gff {output.annotation}
        """
# --------  APPLY FOLLOWING RULES TO EACH SAMPLE

rule get_fastq_files:
    """
    This rule is responsible for downloading the fastq files for each sample. 
    It uses the sratoolkit container to run the fastq-dump command, which downloads the fastq file for a given sample.
    """
    output:
        fastq= TMP + "/raw_fastq/{sample}.fastq"
    container: 
        SRATOOLKIT
    shell:
        """
        mkdir -p {TMP}/raw_fastq
        fasterq-dump --threads {THREADS} --progress {wildcards.sample}
        mv {wildcards.sample}.fastq {output.fastq}
        """
        # Uncomment the lines below to download only 1000 reads per accession with the -X 1000 arg and comment the lines above
        # If you want to download all reads just remove the -X 1000 arg
        # """
        # fastq-dump --stdout -X 1000 {wildcards.sample} > {output.fastq}
        # """

# rule trimming:
#     """
#     This rule is responsible for trimming the fastq files for each sample using trim galore container.
#     """
#     input:
#         fastq= TMP + "/raw_fastq/{sample}.fastq"
#     output:
#         fq= TMP + "/trimmed_fastq/{sample}_trimmed.fq",
#         report= TMP + "/trimmed_fastq/{sample}_trimming_report.txt"
#     container:
#         TRIMGALORE
#     shell:
#         # The fastq files are trimmed usgin trim galore, the output files are then moved to the tmp folder
#         """
#         trim_galore -q 20 --phred33 --length 25 {input.fastq}
#         mv {wildcards.sample}_trimmed.fq {output.fq}
#         mv {wildcards.sample}.fastq_trimming_report.txt {output.report}
#         """

rule create_index:
    """
    This rule is responsible for creating the index for the reference genome using bowtie container.
    """
    input:
        reference= TMP + "/reference.fasta"
    output:
        directory(TMP + "/genome_index")
    container:
        BOWTIE
    shell:
        """
        mkdir -p {output}
        bowtie-build {input.reference} {output}/reference
        """

rule mapping:
    """
    This rule is responsible for mapping the trimmed fastq files to the reference genome using bowtie container.
    """
    input:
        trimmed= TMP + "/raw_fastq/{sample}.fastq",
        genome_index= TMP + "/genome_index"
    output:
        mapped= TMP + "/mapped_reads/{sample}_mapped.sam"
    container: 
        BOWTIE
    shell:
        """
        bowtie --no-unal --threads 4 --sam {input.genome_index}/reference {input.trimmed} {output.mapped}
        """

# --------  APPLY FOLLOWING RULES ONCE AFTER ALL SAMPLES ARE PROCESSED
rule count:
    """
    This rule is responsible for counting the reads mapped to each gene using featureCounts container.
    """
    input:
        reference= TMP +"/annots.gff",
        mapped_sam_files=expand(TMP + "/mapped_reads/{sample}_mapped.sam", sample=SAMPLES)
    output:
        counted= TMP + "/counts.txt"
    container:
        SUBREAD
    shell:
        """
        featureCounts --extraAttributes Name -t gene -g ID -F GTF -T 3 -a {input.reference} -o {output.counted} {input.mapped_sam_files}
        """

rule scriptR:
    """
    This rule is responsible for running the R script that will generate the final plots.
    """
    input:
        counts= TMP + "/counts.txt"
    output:
        expand(RESULTS + "/{plot}.png", plot=PLOTS)
    container:
        RSCRIPT
    shell:
        # This script will generate the final plots and move them to the results folder
        # All files that ends with plot.png are moved to the results folder
        """
        mkdir -p {RESULTS}
        Rscript {WORKFLOW}/scripts/deseq2_script.R {input.counts}
        mv *plot.png {RESULTS}
        """